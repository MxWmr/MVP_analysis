{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86ace4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxw/miniconda3/envs/oceanapp/lib/python3.11/site-packages/seabird/cnv.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 MVP files in the directory: /home/maxw/Documents/ESSTECH25/MVP300_DATA/Stationary_Profiling/\n",
      "MVP data loaded successfully.\n",
      "Found 5 CTD files in the directory: /home/maxw/Documents/ESSTECH25/BATHYSONDE/DATA/TRAIT/NCDF/\n",
      "CTD data loaded successfully.\n",
      "Viscous heating correction done.\n",
      "Surface wave filtering done.\n",
      "Water flow speed computed successfully.\n",
      "CTD data interpolated onto corrected MVP pressure levels.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the parent directory to the path to import MVPAnalyzer\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from MVPAnalyzer import Analyzer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mvpa = Analyzer('/home/maxw/Documents/ESSTECH25/MVP300_DATA/Stationary_Profiling/',subdirs=True)\n",
    "\n",
    "# mvpa.help()\n",
    "\n",
    "mvpa.load_mvp_data(format='ncdf') \n",
    "\n",
    "mvpa.load_ctd_data(format='ncdf',data_path_ctd='/home/maxw/Documents/ESSTECH25/BATHYSONDE/DATA/TRAIT/NCDF/')\n",
    "\n",
    "mvpa.keep_selected_profiles([0, 10, 8, 2], [0, 2, 4, 8])\n",
    "# mvpa.keep_selected_profiles([0,10,8,2])\n",
    "\n",
    "\n",
    "\n",
    "mvpa.viscous_heating_correction()\n",
    "print('Viscous heating correction done.')\n",
    "mvpa.filtering_surface_waves(correction=True)\n",
    "print('Surface wave filtering done.')\n",
    "# mvpa.temporal_lag_correction(correction=True)\n",
    "# print('Temporal lag correction done.')\n",
    "\n",
    "\n",
    "\n",
    "mvpa.compute_waterflow(0.0, corr=True)\n",
    "\n",
    "\n",
    "sqlength = 5000\n",
    "mvpa.interpolate_CTD_and_MVPcorrected(sqlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a56bc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIAGNOSTIC TAILLES PROFILS ===\n",
      "Tailles des profils MVP (avant interpolation):\n",
      "Profil MVP 0: 28877 points\n",
      "Profil MVP 1: 28877 points\n",
      "Profil MVP 2: 28877 points\n",
      "Profil MVP 3: 28877 points\n",
      "Profil MVP 4: 28877 points\n",
      "Profil MVP 5: 28877 points\n",
      "Profil MVP 6: 28877 points\n",
      "Profil MVP 7: 28877 points\n",
      "\n",
      "Apr√®s interpolation (sqlength=5000):\n",
      "Profil 0: 3966 points valides, 1034 NaN sur 5000 total\n",
      "Profil 1: 3962 points valides, 1038 NaN sur 5000 total\n",
      "Profil 2: 4960 points valides, 40 NaN sur 5000 total\n",
      "Profil 3: 4956 points valides, 44 NaN sur 5000 total\n",
      "Profil 4: 4997 points valides, 3 NaN sur 5000 total\n",
      "Profil 5: 4992 points valides, 8 NaN sur 5000 total\n",
      "Profil 6: 4995 points valides, 5 NaN sur 5000 total\n",
      "Profil 7: 4989 points valides, 11 NaN sur 5000 total\n",
      "\n",
      "üí° RECOMMANDATION:\n",
      "   Taille maximale de profil valide: 4997\n",
      "   sqlength actuel: 5000\n",
      "   ‚ö†Ô∏è  R√âDUIRE sqlength √† 4000\n"
     ]
    }
   ],
   "source": [
    "# Nouvelle cellule - DIAGNOSTIC TAILLES\n",
    "print(\"=== DIAGNOSTIC TAILLES PROFILS ===\")\n",
    "\n",
    "# V√©rifier les tailles des profils MVP\n",
    "print(\"Tailles des profils MVP (avant interpolation):\")\n",
    "for i in range(len(mvpa.TEMP_mvp)):\n",
    "    if hasattr(mvpa, 'TEMP_mvp') and i < len(mvpa.TEMP_mvp):\n",
    "        print(f\"Profil MVP {i}: {len(mvpa.TEMP_mvp[i])} points\")\n",
    "\n",
    "# V√©rifier apr√®s interpolation\n",
    "if hasattr(mvpa, 'TEMP_mvp_corr_interp'):\n",
    "    print(f\"\\nApr√®s interpolation (sqlength={sqlength}):\")\n",
    "    for i in range(len(mvpa.TEMP_mvp_corr_interp)):\n",
    "        valid_points = ~np.isnan(mvpa.TEMP_mvp_corr_interp[i])\n",
    "        n_valid = np.sum(valid_points)\n",
    "        n_nan = np.sum(np.isnan(mvpa.TEMP_mvp_corr_interp[i]))\n",
    "        print(f\"Profil {i}: {n_valid} points valides, {n_nan} NaN sur {len(mvpa.TEMP_mvp_corr_interp[i])} total\")\n",
    "\n",
    "# Recommandation\n",
    "max_valid = 0\n",
    "if hasattr(mvpa, 'TEMP_mvp_corr_interp'):\n",
    "    for i in range(len(mvpa.TEMP_mvp_corr_interp)):\n",
    "        n_valid = np.sum(~np.isnan(mvpa.TEMP_mvp_corr_interp[i]))\n",
    "        max_valid = max(max_valid, n_valid)\n",
    "\n",
    "print(f\"\\nüí° RECOMMANDATION:\")\n",
    "print(f\"   Taille maximale de profil valide: {max_valid}\")\n",
    "print(f\"   sqlength actuel: {sqlength}\")\n",
    "if sqlength > max_valid:\n",
    "    recommended = min(max_valid, 4000)  # S√©curit√©\n",
    "    print(f\"   ‚ö†Ô∏è  R√âDUIRE sqlength √† {recommended}\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ sqlength OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64932448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch imported successfully!\n",
      "PyTorch version: 2.8.0\n",
      "CUDA available: True\n",
      "Neural network architecture imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch and neural network components\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    print(\"PyTorch imported successfully!\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    # Import our custom neural network\n",
    "    from utils import prepare_training_data\n",
    "    from architecture import ThermalMassDataset\n",
    "    from train import train_thermal_mass_network\n",
    "    print(\"Neural network architecture imported successfully!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Error importing PyTorch: {e}\")\n",
    "    print(\"Please install PyTorch: pip install torch\")\n",
    "    print(\"Continuing with data preparation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60cd76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8 profiles...\n",
      "Added pair (0,1) - Down: 3966 pts, Up: 3962 pts\n",
      "Added pair (2,3) - Down: 4960 pts, Up: 4956 pts\n",
      "Added pair (4,5) - Down: 4995 pts, Up: 4992 pts\n",
      "Added pair (6,7) - Down: 4994 pts, Up: 4988 pts\n",
      "\n",
      "Prepared 4 valid profile pairs for training\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "from utils import prepare_training_data\n",
    "\n",
    "# Prepare the training data\n",
    "mvp_data, ctd_data = prepare_training_data(mvpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61ca1e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting neural network training...\n",
      "Training neural network with 4 profile pairs...\n",
      "Training set: 3 pairs, Validation set: 1 pairs\n",
      "Using device: cuda\n",
      "Model parameters: 21,176\n",
      "Epoch   1/50: Train Loss: 0.002220, Val Loss: 0.006272\n",
      "Epoch   2/50: Train Loss: 0.002196, Val Loss: 0.006239\n",
      "Epoch   3/50: Train Loss: 0.002187, Val Loss: 0.006203\n",
      "Epoch   4/50: Train Loss: 0.002145, Val Loss: 0.006163\n",
      "Epoch   5/50: Train Loss: 0.002477, Val Loss: 0.006121\n",
      "Epoch   6/50: Train Loss: 0.002111, Val Loss: 0.006090\n",
      "Epoch   7/50: Train Loss: 0.002080, Val Loss: 0.006056\n",
      "Epoch   8/50: Train Loss: 0.002057, Val Loss: 0.006015\n",
      "Epoch   9/50: Train Loss: 0.002041, Val Loss: 0.005965\n",
      "Epoch  10/50: Train Loss: 0.002350, Val Loss: 0.005904\n",
      "Epoch  11/50: Train Loss: 0.002300, Val Loss: 0.005830\n",
      "Epoch  12/50: Train Loss: 0.002255, Val Loss: 0.005742\n",
      "Epoch  13/50: Train Loss: 0.001900, Val Loss: 0.005641\n",
      "Epoch  14/50: Train Loss: 0.001864, Val Loss: 0.005533\n",
      "Epoch  15/50: Train Loss: 0.002132, Val Loss: 0.005435\n",
      "Epoch  16/50: Train Loss: 0.002116, Val Loss: 0.005358\n",
      "Epoch  17/50: Train Loss: 0.001871, Val Loss: 0.005314\n",
      "Epoch  18/50: Train Loss: 0.001845, Val Loss: 0.005337\n",
      "Epoch  19/50: Train Loss: 0.002121, Val Loss: 0.005381\n",
      "Epoch  20/50: Train Loss: 0.001827, Val Loss: 0.005436\n",
      "Epoch  21/50: Train Loss: 0.001836, Val Loss: 0.005452\n",
      "Epoch  22/50: Train Loss: 0.001817, Val Loss: 0.005464\n",
      "Epoch  23/50: Train Loss: 0.001822, Val Loss: 0.005440\n",
      "Epoch  24/50: Train Loss: 0.002107, Val Loss: 0.005459\n",
      "Epoch  25/50: Train Loss: 0.001815, Val Loss: 0.005447\n",
      "Epoch  26/50: Train Loss: 0.001806, Val Loss: 0.005433\n",
      "Epoch  27/50: Train Loss: 0.001806, Val Loss: 0.005422\n",
      "Epoch  28/50: Train Loss: 0.001809, Val Loss: 0.005406\n",
      "Epoch  29/50: Train Loss: 0.001798, Val Loss: 0.005404\n",
      "Epoch  30/50: Train Loss: 0.001795, Val Loss: 0.005443\n",
      "Epoch  31/50: Train Loss: 0.001806, Val Loss: 0.005438\n",
      "Epoch  32/50: Train Loss: 0.001797, Val Loss: 0.005434\n",
      "Epoch  33/50: Train Loss: 0.001792, Val Loss: 0.005428\n",
      "Epoch  34/50: Train Loss: 0.002091, Val Loss: 0.005418\n",
      "Epoch  35/50: Train Loss: 0.001797, Val Loss: 0.005440\n",
      "Epoch  36/50: Train Loss: 0.001796, Val Loss: 0.005424\n",
      "Epoch  37/50: Train Loss: 0.001787, Val Loss: 0.005403\n",
      "Epoch  38/50: Train Loss: 0.001794, Val Loss: 0.005386\n",
      "Epoch  39/50: Train Loss: 0.001785, Val Loss: 0.005341\n",
      "Epoch  40/50: Train Loss: 0.002067, Val Loss: 0.005338\n",
      "Epoch  41/50: Train Loss: 0.001790, Val Loss: 0.005334\n",
      "Epoch  42/50: Train Loss: 0.002061, Val Loss: 0.005332\n",
      "Epoch  43/50: Train Loss: 0.001774, Val Loss: 0.005327\n",
      "Epoch  44/50: Train Loss: 0.002057, Val Loss: 0.005356\n",
      "Epoch  45/50: Train Loss: 0.001774, Val Loss: 0.005350\n",
      "Epoch  46/50: Train Loss: 0.002062, Val Loss: 0.005345\n",
      "Epoch  47/50: Train Loss: 0.001776, Val Loss: 0.005337\n",
      "Epoch  48/50: Train Loss: 0.001785, Val Loss: 0.005332\n",
      "Epoch  49/50: Train Loss: 0.001778, Val Loss: 0.005329\n",
      "Epoch  50/50: Train Loss: 0.001765, Val Loss: 0.005330\n",
      "Model saved as 'thermal_mass_model.pth'\n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "import importlib\n",
    "importlib.reload(train)\n",
    "from train import train_thermal_mass_network\n",
    "\n",
    "# Train the model if we have data and PyTorch is available\n",
    "if 'torch' in globals() and len(mvp_data['TEMP_down']) > 0:\n",
    "    print(\"Starting neural network training...\")\n",
    "    trained_model, train_losses, val_losses = train_thermal_mass_network(mvp_data, ctd_data,                                                                         \n",
    "                                                                        num_epochs=50)\n",
    "    \n",
    "    if trained_model is not None:\n",
    "        print(\"Training completed successfully!\")\n",
    "    else:\n",
    "        print(\"Training failed.\")\n",
    "else:\n",
    "    print(\"Skipping training: PyTorch not available or no data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f39cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n============================================================\n",
      "TRAINING ANALYSIS\n",
      "============================================================\n",
      "\\nPredicted parameters for profile pair 0:\n",
      "==================================================\n",
      "alpha0_down : 0.158234\n",
      "alphaS_down : 0.143503\n",
      "tau0_down   : 4.585765\n",
      "tauS_down   : 0.113654\n",
      "alpha0_up   : -0.028670\n",
      "alphaS_up   : -0.044593\n",
      "tau0_up     : 4.570117\n",
      "tauS_up     : 0.027972\n"
     ]
    }
   ],
   "source": [
    "# Analyze training results and test the trained model\n",
    "def analyze_training_results(train_losses, val_losses=None):\n",
    "    \"\"\"Plot training curves and analyze results\"\"\"\n",
    "    if train_losses is None:\n",
    "        print(\"No training results to analyze\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Training curves\n",
    "    plt.subplot(1, 2, 1)\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    if val_losses is not None:\n",
    "        plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    # Loss statistics\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.text(0.1, 0.9, f\"Final Training Loss: {train_losses[-1]:.6f}\", transform=plt.gca().transAxes)\n",
    "    if val_losses is not None:\n",
    "        plt.text(0.1, 0.8, f\"Final Validation Loss: {val_losses[-1]:.6f}\", transform=plt.gca().transAxes)\n",
    "    plt.text(0.1, 0.7, f\"Min Training Loss: {min(train_losses):.6f}\", transform=plt.gca().transAxes)\n",
    "    plt.text(0.1, 0.6, f\"Total Epochs: {len(train_losses)}\", transform=plt.gca().transAxes)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.axis('off')\n",
    "    plt.title('Training Statistics')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def test_model_predictions(model, mvp_data, ctd_data, test_idx=0):\n",
    "    \"\"\"Test the model on a specific profile pair\"\"\"\n",
    "    if model is None:\n",
    "        print(\"No trained model available\")\n",
    "        return\n",
    "    \n",
    "    if test_idx >= len(mvp_data['TEMP_down']):\n",
    "        print(f\"Test index {test_idx} not available\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        device = next(model.parameters()).device\n",
    "        \n",
    "        # Prepare test data\n",
    "        dataset = ThermalMassDataset(mvp_data, ctd_data)\n",
    "        test_sample = dataset[test_idx]\n",
    "        \n",
    "        # Add batch dimension\n",
    "        input_features = test_sample['input_features'].unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predicted_params = model(input_features)\n",
    "        \n",
    "        # Extract parameters\n",
    "        params = predicted_params[0].cpu().numpy()\n",
    "        param_names = ['alpha0_down', 'alphaS_down', 'tau0_down', 'tauS_down',\n",
    "                       'alpha0_up', 'alphaS_up', 'tau0_up', 'tauS_up']\n",
    "        \n",
    "        print(f\"\\\\nPredicted parameters for profile pair {test_idx}:\")\n",
    "        print(\"=\" * 50)\n",
    "        for name, value in zip(param_names, params):\n",
    "            print(f\"{name:12s}: {value:.6f}\")\n",
    "        \n",
    "        # Visualize parameters\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        down_params = params[:4]\n",
    "        up_params = params[4:]\n",
    "        x = np.arange(4)\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, down_params, width, label='Downcast', alpha=0.7)\n",
    "        plt.bar(x + width/2, up_params, width, label='Upcast', alpha=0.7)\n",
    "        plt.xlabel('Parameter')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Thermal Mass Correction Parameters')\n",
    "        plt.xticks(x, ['Œ±‚ÇÄ', 'Œ±‚Çõ', 'œÑ‚ÇÄ', 'œÑ‚Çõ'])\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Parameter interpretation\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.text(0.1, 0.9, \"Parameter Interpretation:\", transform=plt.gca().transAxes, fontweight='bold')\n",
    "        plt.text(0.1, 0.8, f\"Œ±‚ÇÄ: Amplitude at surface\", transform=plt.gca().transAxes)\n",
    "        plt.text(0.1, 0.7, f\"Œ±‚Çõ: Salinity dependence of amplitude\", transform=plt.gca().transAxes)\n",
    "        plt.text(0.1, 0.6, f\"œÑ‚ÇÄ: Time constant at surface\", transform=plt.gca().transAxes)\n",
    "        plt.text(0.1, 0.5, f\"œÑ‚Çõ: Salinity dependence of time constant\", transform=plt.gca().transAxes)\n",
    "        plt.text(0.1, 0.3, \"Garau et al. 2011 formula:\", transform=plt.gca().transAxes, fontweight='bold')\n",
    "        plt.text(0.1, 0.2, \"C_corr = C + Œ±¬∑œÑ¬∑(dT/dt) - (C_prev - C)¬∑exp(-dt/œÑ)\", transform=plt.gca().transAxes, fontsize=10)\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Analyze results if training was successful\n",
    "if 'trained_model' in locals() and trained_model is not None:\n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    analyze_training_results(train_losses, val_losses if 'val_losses' in locals() else None)\n",
    "    \n",
    "    # Test model on first profile\n",
    "    if len(mvp_data['TEMP_down']) > 0:\n",
    "        predicted_params = test_model_predictions(trained_model, mvp_data, ctd_data, test_idx=0)\n",
    "else:\n",
    "    print(\"No trained model to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40548934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import garau_correction_nograd\n",
    "\n",
    "id = 2\n",
    "\n",
    "device = next(trained_model.parameters()).device\n",
    "\n",
    "# Prepare test data\n",
    "dataset = ThermalMassDataset(mvp_data, ctd_data)\n",
    "test_sample = dataset[id]\n",
    "\n",
    "# Add batch dimension\n",
    "input_features = test_sample['input_features'].unsqueeze(0).to(device)\n",
    "\n",
    "# Get model predictions\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_params = trained_model(input_features)\n",
    "\n",
    "# Extract parameters\n",
    "params = predicted_params[0].cpu().numpy()\n",
    "param_names = ['alpha0_down', 'alphaS_down', 'tau0_down', 'tauS_down',\n",
    "                'alpha0_up', 'alphaS_up', 'tau0_up', 'tauS_up']\n",
    "\n",
    "\n",
    "\n",
    "T_down_corr = garau_correction_nograd(mvpa.TEMP_mvp_corr_interp[id], mvpa.COND_mvp_corr_interp[id], mvpa.PRES_mvp_corr_interp[id],\n",
    "                               mvpa.SPEED_mvp_corr_interp[id],params[0],params[1],\n",
    "                               params[2],params[3])\n",
    "T_up_corr = garau_correction_nograd(mvpa.TEMP_mvp_corr_interp[id+1], mvpa.COND_mvp_corr_interp[id+1], mvpa.PRES_mvp_corr_interp[id+1],\n",
    "                             mvpa.SPEED_mvp_corr_interp[id+1],params[4],params[5],\n",
    "                             params[6],params[7])\n",
    "\n",
    "import gsw\n",
    "S_down_corr = gsw.SP_from_C(mvpa.COND_mvp_corr_interp[id], mvpa.TEMP_mvp_corr_interp[id], mvpa.PRES_mvp_corr_interp[id])\n",
    "S_down_nn = gsw.SP_from_C(mvpa.COND_mvp_corr_interp[id], T_down_corr, mvpa.PRES_mvp_corr_interp[id])\n",
    "S_up_corr = gsw.SP_from_C(mvpa.COND_mvp_corr_interp[id+1], mvpa.TEMP_mvp_corr_interp[id+1], mvpa.PRES_mvp_corr_interp[id+1])\n",
    "S_up_nn = gsw.SP_from_C(mvpa.COND_mvp_corr_interp[id+1], T_up_corr, mvpa.PRES_mvp_corr_interp[id+1])\n",
    "\n",
    "%matplotlib tk\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(S_down_corr, mvpa.PRES_mvp_corr_interp[id], label='S down corrected (Garau)')\n",
    "plt.plot(S_down_nn, mvpa.PRES_mvp_corr_interp[id], label='S down corrected (NN)')\n",
    "plt.plot(S_up_corr, mvpa.PRES_mvp_corr_interp[id+1], label='S up corrected (Garau)')\n",
    "plt.plot(S_up_nn, mvpa.PRES_mvp_corr_interp[id+1], label='S up corrected (NN)')\n",
    "plt.plot(mvpa.SALT_ctd_on_mvp[id], mvpa.PRES_mvp_corr_interp[id], 'k--', label='CTD Salinity down')\n",
    "plt.plot(mvpa.SALT_ctd_on_mvp[id+1], mvpa.PRES_mvp_corr_interp[id+1], 'k-.', label='CTD Salinity up')\n",
    "plt.gca().invert_yaxis()                                                                  \n",
    "plt.xlabel('Salinity (g/kg)')\n",
    "plt.ylabel('Pressure (dbar)')\n",
    "plt.title('Salinity Profiles Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oceanapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
